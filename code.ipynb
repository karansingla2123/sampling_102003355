{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('Creditcard_data.csv')\n",
    "\n",
    "# Separate the feature matrix X and the target variable y\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Apply random oversampling to balance the classes\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Create a new DataFrame with the resampled data\n",
    "resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "resampled_df['Class'] = y_resampled\n",
    "\n",
    "# Write the resampled DataFrame to a new CSV file\n",
    "resampled_df.to_csv('balanced_dataf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "data = pd.read_csv('balanced_dataf.csv')\n",
    "\n",
    "X1 = data.drop('Class', axis=1)\n",
    "y1 = data['Class']\n",
    "N = len(data)\n",
    "p = 0.5\n",
    "c = 0.95  # desired confidence level\n",
    "e = 0.05  # desired margin of error\n",
    "\n",
    "z = 1.96  # z-score for 95% confidence level\n",
    "n = math.ceil((z**2 * p * (1-p)) / e**2)\n",
    "\n",
    "# Set the sample size\n",
    "sample_size = n  # Set the desired sample size\n",
    "X_sampled = X1.sample(n=sample_size, random_state=0)\n",
    "y_sampled = y1[X_sampled.index]  # Match the sampled output variable with the sampled input variables\n",
    "    \n",
    "# Combine the sampled input and output variables into a single DataFrame\n",
    "sampled_df = pd.concat([X_sampled, y_sampled], axis=1)\n",
    "    \n",
    "# Save the sampled DataFrame to a CSV file\n",
    "sampled_df.to_csv(f'simple_random_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('balanced_dataf.csv')\n",
    "\n",
    "# Separate the feature matrix X and the target variable y\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Determine the number of strata (in this case, we use a binary target variable, so there are two strata)\n",
    "num_strata = 2\n",
    "\n",
    "# Initialize an empty list to store the stratified samples\n",
    "samples = []\n",
    "\n",
    "# Loop over each stratum\n",
    "for i in range(num_strata):\n",
    "    # Subset the data to include only the observations in the current stratum\n",
    "    stratum_data = df[df['Class'] == i]\n",
    "    \n",
    "    # Calculate the sample size for the current stratum\n",
    "    stratum_size = len(stratum_data)\n",
    "    population_size = len(df)\n",
    "    desired_margin_of_error = 0.05\n",
    "    confidence_level = 0.95\n",
    "    z_score = 1.96  # for a 95% confidence level\n",
    "    p = stratum_size / population_size\n",
    "    q = 1 - p\n",
    "    n = (z_score**2 * p * q * population_size) / ((z_score**2 * p * q) + (desired_margin_of_error**2 * (population_size-1)))\n",
    "    n = math.ceil(n)\n",
    "    \n",
    "    # If the calculated sample size for the current stratum is greater than the number of observations in the stratum, set the sample size to the number of observations\n",
    "    if n > stratum_size:\n",
    "        n = stratum_size\n",
    "    \n",
    "    # Randomly select observations from the current stratum to include in the sample\n",
    "    sample_indices = np.random.choice(stratum_data.index, size=n, replace=False)\n",
    "    stratum_sample = stratum_data.loc[sample_indices]\n",
    "    \n",
    "    # Add the current stratum sample to the list of stratified samples\n",
    "    samples.append(stratum_sample)\n",
    "\n",
    "# Combine the stratified samples into a single DataFrame\n",
    "stratified_sample = pd.concat(samples)\n",
    "\n",
    "# Write the stratified sample to a new CSV file\n",
    "stratified_sample.to_csv('stratified_sample.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('balanced_dataf.csv')\n",
    "\n",
    "# Define the cluster size\n",
    "C = 100\n",
    "\n",
    "# Calculate the number of clusters\n",
    "n_clusters = math.ceil(len(data)/C)\n",
    "\n",
    "# Create a KMeans object with the calculated number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "# Fit the KMeans object to the data\n",
    "kmeans.fit(data.drop('Class', axis=1))\n",
    "\n",
    "# Add the cluster labels to the data\n",
    "data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Calculate the sample size\n",
    "z = 1.96\n",
    "p = 0.5\n",
    "e = 0.05\n",
    "s = 1\n",
    "N = len(data)\n",
    "C = 2\n",
    "n = math.ceil((z**2 * p * (1-p) * (N/C)) / ((e**2) + ((z**2 * p * (1-p))/(C-1))))\n",
    "\n",
    "# Create an empty dataframe to hold the sample\n",
    "sample = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# Loop through each cluster\n",
    "for i in range(n_clusters):\n",
    "    # Get the data for the current cluster\n",
    "    cluster_data = data[data['Cluster'] == i]\n",
    "    cluster_size = len(cluster_data)\n",
    "    cluster_sample_size = math.ceil((cluster_size/N)*n)\n",
    "    if cluster_sample_size > cluster_size:\n",
    "         cluster_sample_size = cluster_size\n",
    "        \n",
    "    # Sample from the current cluster\n",
    "    cluster_sample = cluster_data.sample(n=cluster_sample_size, replace=False)\n",
    "    \n",
    "    # Add the cluster sample to the overall sample dataframe\n",
    "    sample = pd.concat([sample, cluster_sample])\n",
    "\n",
    "# Remove the cluster column from the sample\n",
    "sample = sample.drop('Cluster', axis=1)\n",
    "\n",
    "# Save the sample to a CSV file\n",
    "sample.to_csv('cluster_sample_dataset.csv', index=False)\n",
    "\n",
    "    \n",
    "    # If the cluster sample size is larger than the cluster size, set it to the cluster size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load the dataset \"Creditcard_data\" into a Pandas dataframe\n",
    "df = pd.read_csv('balanced_dataf.csv')\n",
    "\n",
    "# Calculate the number of rows in the dataset\n",
    "n = len(df)\n",
    "\n",
    "# Set the sampling interval \"k\" as the square root of the number of rows in the dataset\n",
    "k = int(math.sqrt(n))\n",
    "\n",
    "# Select every \"k\" row starting from a random index in the dataset\n",
    "sample = df.iloc[::k]\n",
    "\n",
    "# Print the first few rows of the sample\n",
    "sample.to_csv('systematic_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convinence sampling\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open('balanced_dataf.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    # Skip the header row\n",
    "    next(reader)\n",
    "    # Create a list of all the data rows\n",
    "    data_rows = list(reader)\n",
    "\n",
    "# Choose a sample size of 100\n",
    "sample_size = 100\n",
    "\n",
    "# Use convenience sampling to randomly select the desired number of rows\n",
    "sample = random.sample(data_rows, sample_size)\n",
    "\n",
    "s=pd.DataFrame(sample)\n",
    "s.to_csv('convinence_dataset.csv', header=['Time','V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount','Class'],index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9913793103448276\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the CSV file into a pandas dataframe\n",
    "data = pd.read_csv('simple_random_dataset.csv')\n",
    "list1=[]\n",
    "# split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# create a random forest classifier model and fit it to the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train.drop('Class', axis=1), train['Class'])\n",
    "\n",
    "# predict the output values for the testing data\n",
    "predictions = model.predict(test.drop('Class', axis=1))\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "list1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891891891891892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the CSV file into a pandas dataframe\n",
    "data = pd.read_csv('stratified_sample.csv')\n",
    "# split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# create a random forest classifier model and fit it to the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train.drop('Class', axis=1), train['Class'])\n",
    "\n",
    "# predict the output values for the testing data\n",
    "predictions = model.predict(test.drop('Class', axis=1))\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "list1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the CSV file into a pandas dataframe\n",
    "data = pd.read_csv('systematic_dataset.csv')\n",
    "# split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# create a random forest classifier model and fit it to the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train.drop('Class', axis=1), train['Class'])\n",
    "\n",
    "# predict the output values for the testing data\n",
    "predictions = model.predict(test.drop('Class', axis=1))\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "list1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9956709956709957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the CSV file into a pandas dataframe\n",
    "data = pd.read_csv('cluster_sample_dataset.csv')\n",
    "# split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# create a random forest classifier model and fit it to the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train.drop('Class', axis=1), train['Class'])\n",
    "\n",
    "# predict the output values for the testing data\n",
    "predictions = model.predict(test.drop('Class', axis=1))\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "list1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the CSV file into a pandas dataframe\n",
    "data = pd.read_csv('convinence_dataset.csv')\n",
    "# split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# create a random forest classifier model and fit it to the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train.drop('Class', axis=1), train['Class'])\n",
    "\n",
    "# predict the output values for the testing data\n",
    "predictions = model.predict(test.drop('Class', axis=1))\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "list1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.948051948051948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('simple_random_dataset.csv')\n",
    "list2=[]\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list2.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9435483870967742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('stratified_sample.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list2.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('systematic_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list2.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961038961038961\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('cluster_sample_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list2.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('convinence_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list2.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('simple_random_dataset.csv')\n",
    "list3=[]\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list3.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9354838709677419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('stratified_sample.csv')\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list3.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('systematic_dataset.csv')\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list3.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('cluster_sample_dataset.csv')\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list3.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('convinence_dataset.csv')\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list3.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('simple_random_dataset.csv')\n",
    "list4=[]\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list4.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6935483870967742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('stratified_sample.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list4.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('systematic_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list4.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('cluster_sample_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list4.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('convinence_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list4.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987012987012987\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('simple_random_dataset.csv')\n",
    "list5=[]\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list5.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9919354838709677\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('stratified_sample.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list5.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('systematic_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list5.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9935064935064936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('cluster_sample_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list5.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from a CSV file into a Pandas dataframe\n",
    "data = pd.read_csv('convinence_dataset.csv')\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "list5.append(accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([list1,list2,list3,list4,list5],columns=['Random sampling','Stratified sampling','Systematic sampling','Cluster sampling','Convenience sampling'],index=['Random forest','K-nearest neighour(KNN)','support vector machine(SVM)','Naive bayes','Decision Tree'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random sampling</th>\n",
       "      <th>Stratified sampling</th>\n",
       "      <th>Systematic sampling</th>\n",
       "      <th>Cluster sampling</th>\n",
       "      <th>Convenience sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.995671</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-nearest neighour(KNN)</th>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support vector machine(SVM)</th>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive bayes</th>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Random sampling  Stratified sampling  \\\n",
       "Random forest                       0.991379             0.989189   \n",
       "K-nearest neighour(KNN)             0.948052             0.943548   \n",
       "support vector machine(SVM)         0.935065             0.935484   \n",
       "Naive bayes                         0.779221             0.693548   \n",
       "Decision Tree                       0.987013             0.991935   \n",
       "\n",
       "                             Systematic sampling  Cluster sampling  \\\n",
       "Random forest                           0.916667          0.995671   \n",
       "K-nearest neighour(KNN)                 0.500000          0.961039   \n",
       "support vector machine(SVM)             0.750000          0.909091   \n",
       "Naive bayes                             0.875000          0.753247   \n",
       "Decision Tree                           0.875000          0.993506   \n",
       "\n",
       "                             Convenience sampling  \n",
       "Random forest                            0.966667  \n",
       "K-nearest neighour(KNN)                  0.750000  \n",
       "support vector machine(SVM)              0.850000  \n",
       "Naive bayes                              0.700000  \n",
       "Decision Tree                            0.850000  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8b294_row0_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8b294\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8b294_level0_col0\" class=\"col_heading level0 col0\" >Random sampling</th>\n",
       "      <th id=\"T_8b294_level0_col1\" class=\"col_heading level0 col1\" >Stratified sampling</th>\n",
       "      <th id=\"T_8b294_level0_col2\" class=\"col_heading level0 col2\" >Systematic sampling</th>\n",
       "      <th id=\"T_8b294_level0_col3\" class=\"col_heading level0 col3\" >Cluster sampling</th>\n",
       "      <th id=\"T_8b294_level0_col4\" class=\"col_heading level0 col4\" >Convenience sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8b294_level0_row0\" class=\"row_heading level0 row0\" >Random forest</th>\n",
       "      <td id=\"T_8b294_row0_col0\" class=\"data row0 col0\" >0.991379</td>\n",
       "      <td id=\"T_8b294_row0_col1\" class=\"data row0 col1\" >0.989189</td>\n",
       "      <td id=\"T_8b294_row0_col2\" class=\"data row0 col2\" >0.916667</td>\n",
       "      <td id=\"T_8b294_row0_col3\" class=\"data row0 col3\" >0.995671</td>\n",
       "      <td id=\"T_8b294_row0_col4\" class=\"data row0 col4\" >0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b294_level0_row1\" class=\"row_heading level0 row1\" >K-nearest neighour(KNN)</th>\n",
       "      <td id=\"T_8b294_row1_col0\" class=\"data row1 col0\" >0.948052</td>\n",
       "      <td id=\"T_8b294_row1_col1\" class=\"data row1 col1\" >0.943548</td>\n",
       "      <td id=\"T_8b294_row1_col2\" class=\"data row1 col2\" >0.500000</td>\n",
       "      <td id=\"T_8b294_row1_col3\" class=\"data row1 col3\" >0.961039</td>\n",
       "      <td id=\"T_8b294_row1_col4\" class=\"data row1 col4\" >0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b294_level0_row2\" class=\"row_heading level0 row2\" >support vector machine(SVM)</th>\n",
       "      <td id=\"T_8b294_row2_col0\" class=\"data row2 col0\" >0.935065</td>\n",
       "      <td id=\"T_8b294_row2_col1\" class=\"data row2 col1\" >0.935484</td>\n",
       "      <td id=\"T_8b294_row2_col2\" class=\"data row2 col2\" >0.750000</td>\n",
       "      <td id=\"T_8b294_row2_col3\" class=\"data row2 col3\" >0.909091</td>\n",
       "      <td id=\"T_8b294_row2_col4\" class=\"data row2 col4\" >0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b294_level0_row3\" class=\"row_heading level0 row3\" >Naive bayes</th>\n",
       "      <td id=\"T_8b294_row3_col0\" class=\"data row3 col0\" >0.779221</td>\n",
       "      <td id=\"T_8b294_row3_col1\" class=\"data row3 col1\" >0.693548</td>\n",
       "      <td id=\"T_8b294_row3_col2\" class=\"data row3 col2\" >0.875000</td>\n",
       "      <td id=\"T_8b294_row3_col3\" class=\"data row3 col3\" >0.753247</td>\n",
       "      <td id=\"T_8b294_row3_col4\" class=\"data row3 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b294_level0_row4\" class=\"row_heading level0 row4\" >Decision Tree</th>\n",
       "      <td id=\"T_8b294_row4_col0\" class=\"data row4 col0\" >0.987013</td>\n",
       "      <td id=\"T_8b294_row4_col1\" class=\"data row4 col1\" >0.991935</td>\n",
       "      <td id=\"T_8b294_row4_col2\" class=\"data row4 col2\" >0.875000</td>\n",
       "      <td id=\"T_8b294_row4_col3\" class=\"data row4 col3\" >0.993506</td>\n",
       "      <td id=\"T_8b294_row4_col4\" class=\"data row4 col4\" >0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244e34ea710>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(data):\n",
    "    is_max = data == np.nanmax(df.values)\n",
    "    return ['background-color: red' if v else '' for v in is_max]\n",
    "\n",
    "# Apply the custom function to the entire dataframe and display the styled dataframe\n",
    "df.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('finaltable.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a08f583acb35847448b52a9eb69292a61cb88f49696fc3f852078c09d98ba127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
